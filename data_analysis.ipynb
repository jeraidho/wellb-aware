{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a206a9f-a353-430c-a787-40fb7ed397c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22290/2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f58c9ed-4fc2-4606-a594-0826f56cf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('RU_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79ef039-7c51-4531-9c30-ae7a25f1b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'Texts', 1:'Annotation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed950b3e-4933-4d2b-aff5-a43efcb44e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "      <th>Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12885</th>\n",
       "      <td>У меня ничего не осталось. Моя девушка, с которой мы встречались почти три года, только что разорвала наши отношения, потому что ей кажется, что она не способна любить меня так же, как я люблю ее. Я потерял маму в сентябре 2017 года, когда моя девушка держала меня за руку. Мне не ради чего жить, я планировал свою жизнь после окончания школы вокруг нее, а теперь остался в руинах и одинок. У меня ничего не осталось, нет человека, который мог бы меня понять и полюбить, и не для кого работать. Я просто хочу через какое-то время проползти и умереть.</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30522</th>\n",
       "      <td>До сих пор я не осознавал, что у меня такая серьезная проблема. Я просто смотрел на кучу таблеток минут пятнадцать. Я в порядке? Я вполне обоснованно думаю, что скоро сделаю это, и мне, вероятно, не помешал бы какой-нибудь совет.</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25852</th>\n",
       "      <td>Мне больше не нравится ПРЛ, мой разум — это все, чем я являюсь, если у меня его нет, то у меня нет ничего. я только что причинил боль кому-то другому, кто только и делал, что заботился обо мне, потому что я, черт возьми, не могу контролировать свои чувства, клянусь, мне больше нельзя позволять существовать. я отпускаю</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10489</th>\n",
       "      <td>Раскрой икры, если кто-то напомнит мне, что я знаю, что вы, милашки, хотите увидеть аккуратные икры</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39444</th>\n",
       "      <td>пригласите меня на свои серверы Discord, спасибо</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Texts  \\\n",
       "12885  У меня ничего не осталось. Моя девушка, с которой мы встречались почти три года, только что разорвала наши отношения, потому что ей кажется, что она не способна любить меня так же, как я люблю ее. Я потерял маму в сентябре 2017 года, когда моя девушка держала меня за руку. Мне не ради чего жить, я планировал свою жизнь после окончания школы вокруг нее, а теперь остался в руинах и одинок. У меня ничего не осталось, нет человека, который мог бы меня понять и полюбить, и не для кого работать. Я просто хочу через какое-то время проползти и умереть.   \n",
       "30522                                                                                                                                                                                                                                                                                                                                   До сих пор я не осознавал, что у меня такая серьезная проблема. Я просто смотрел на кучу таблеток минут пятнадцать. Я в порядке? Я вполне обоснованно думаю, что скоро сделаю это, и мне, вероятно, не помешал бы какой-нибудь совет.   \n",
       "25852                                                                                                                                                                                                                                         Мне больше не нравится ПРЛ, мой разум — это все, чем я являюсь, если у меня его нет, то у меня нет ничего. я только что причинил боль кому-то другому, кто только и делал, что заботился обо мне, потому что я, черт возьми, не могу контролировать свои чувства, клянусь, мне больше нельзя позволять существовать. я отпускаю   \n",
       "10489                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Раскрой икры, если кто-то напомнит мне, что я знаю, что вы, милашки, хотите увидеть аккуратные икры   \n",
       "39444                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        пригласите меня на свои серверы Discord, спасибо   \n",
       "\n",
       "        Annotation  \n",
       "12885      suicide  \n",
       "30522      suicide  \n",
       "25852      suicide  \n",
       "10489  non-suicide  \n",
       "39444  non-suicide  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643a2938-8d01-4f2c-84ec-9cd2208accff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['suicide', 'non-suicide'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Annotation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4443c84e-f3b2-4855-803b-21b899a1a26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Бывшая жена угрожает самоубийством Недавно я н...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Я странный? На меня не влияют комплименты, есл...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Наконец-то 2020 год почти закончился... Так чт...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>мне нужна помощь, просто помоги мне, я так плачу</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Я так растеряна. Здравствуйте, меня зовут Адам...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47992</th>\n",
       "      <td>Я только что увидел забавный мем, прежде чем п...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47993</th>\n",
       "      <td>Я боюсь, мне некому рассказать. У меня инфекци...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47994</th>\n",
       "      <td>Педофилия, членовредительство и мысли о самоуб...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>Я больше не могу справляться. Почти 2 месяца н...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>Мне нужен кто-то, кто сделает сюрприз моему дв...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Texts   Annotation  Target\n",
       "0      Бывшая жена угрожает самоубийством Недавно я н...      suicide       1\n",
       "1      Я странный? На меня не влияют комплименты, есл...  non-suicide       0\n",
       "2      Наконец-то 2020 год почти закончился... Так чт...  non-suicide       0\n",
       "3       мне нужна помощь, просто помоги мне, я так плачу      suicide       1\n",
       "4      Я так растеряна. Здравствуйте, меня зовут Адам...      suicide       1\n",
       "...                                                  ...          ...     ...\n",
       "47992  Я только что увидел забавный мем, прежде чем п...      suicide       1\n",
       "47993  Я боюсь, мне некому рассказать. У меня инфекци...  non-suicide       0\n",
       "47994  Педофилия, членовредительство и мысли о самоуб...      suicide       1\n",
       "47995  Я больше не могу справляться. Почти 2 месяца н...      suicide       1\n",
       "47996  Мне нужен кто-то, кто сделает сюрприз моему дв...  non-suicide       0\n",
       "\n",
       "[47997 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'] = df['Annotation'].apply(lambda x: 1 if x=='suicide' else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bf53b",
   "metadata": {},
   "source": [
    "## Data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840d7004-da72-4a05-b315-26d5414d4061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation\n",
       "non-suicide    24081\n",
       "suicide        23916\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be777c70-6b3f-4cd0-a915-738b8faf73da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Texts'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5d0158-68bd-4e78-a9fc-a90934af9fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Texts, Annotation, Target]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Texts'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fabd16e-dcb2-4fb4-8354-f85f1e08c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e5b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5773ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Annotation'].value_counts().plot(kind='pie', autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e773b-0b27-4cf6-be24-2b52c55e1d16",
   "metadata": {},
   "source": [
    "*vectorizers*: tf-idf, word2vec\n",
    "*classifiers*: kNN, LogisticRegressionClassifier, Naive Bayes, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36ba08b-345d-47da-bd6e-f0b8abde2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/byakubson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# let's implement preprocess: tokenization, filter by stopwords, normal form\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "nltk.download('punkt')\n",
    "sw = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b173cb-a797-42cf-8a86-88b064090719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_normal(doc):\n",
    "    words = [morph.parse(word.lower())[0].normal_form for word in word_tokenize(doc) if word.isalpha()]\n",
    "    filtered = [word for word in words if word not in sw]\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06717404-cdf3-44ce-b7f2-59d26c633e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokenize(doc):\n",
    "    words = [word.lower() for word in word_tokenize(doc) if word.isalpha()]\n",
    "    filtered = [word for word in words if word not in sw]\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad46ee6-71d6-440b-883e-78e39299f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "287beb1d-8d5f-4630-8416-2f89aab8092c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ec56ff3cf34fe59882817332ccb160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=11999), Label(value='0 / 11999')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22290/3381015055.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokenised'] = df['Texts'].parallel_apply(preprocess_tokenize)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b9f3b3bf784c09bfe27b7109aef498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=11999), Label(value='0 / 11999')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22290/3381015055.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Normalised'] = df['Texts'].parallel_apply(preprocess_normal)\n"
     ]
    }
   ],
   "source": [
    "df['Tokenised'] = df['Texts'].parallel_apply(preprocess_tokenize)\n",
    "df['Normalised'] = df['Texts'].parallel_apply(preprocess_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6703f5-8175-4720-b24a-6192025c0446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texts</th>\n",
       "      <th>Tokenised</th>\n",
       "      <th>Normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47510</th>\n",
       "      <td>Мне просто нужна помощь прямо сейчас, я не знаю, что сказать, я просто не могу перестать плакать и боюсь</td>\n",
       "      <td>просто нужна помощь прямо знаю сказать просто могу перестать плакать боюсь</td>\n",
       "      <td>просто нужный помощь прямо знать сказать просто мочь перестать плакать бояться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9847</th>\n",
       "      <td>Google Meet - это глупо, как будто я захожу на это уже второй час и нажимаю кнопку выключения камеры, прежде чем вы уходите, чтобы присоединиться (как я почти уверен, что 99,9% этого сабвуфера так и делают), и эта кнопка выключила мою камеру в Экран присоединения к собранию, и он НЕ РАБОТАЕТ. Это привело меня на встречу с включенной камерой. Я не могу физически выразить, насколько мне не понравился этот опыт.</td>\n",
       "      <td>google meet это глупо захожу это второй час нажимаю кнопку выключения камеры прежде уходите присоединиться уверен сабвуфера делают эта кнопка выключила мою камеру экран присоединения собранию работает это привело встречу включенной камерой могу физически выразить насколько понравился опыт</td>\n",
       "      <td>google meet это глупо заходить это второй час нажимать кнопка выключение камера прежде уходить присоединиться уверенный это сабвуфер делать кнопка выключить камера экран присоединение собрание работать это привести встреча включить камера мочь физически выразить насколько понравиться опыт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>леденец – забавное название. я даже не знаю, как они называются\\n\\nя ем один прямо сейчас, спустя примерно 3 года. У меня были действительно странные правила питания, которые включали только питьевую воду и энергетические напитки. я видел в этом фруктовом мороженое замороженный сок, поэтому просто не стал его есть\\n\\nочевидно, я не следовал своим «правилам» на 100%, но по какой-то причине это действительно прижилось, но посмотрите на меня сейчас\\n\\nна самом деле это действительно смешно. я бы отказался от мороженого в жаркий летний день, а затем в ту же ночь выпил бы в четыре раза больше калорий, чем алкоголь\\n\\nя не знаю, как мой разум так работал, но это так</td>\n",
       "      <td>леденец забавное название знаю называются ем прямо спустя примерно года действительно странные правила питания которые включали питьевую воду энергетические напитки видел фруктовом мороженое замороженный сок поэтому просто стал очевидно следовал своим правилам причине это действительно прижилось посмотрите самом деле это действительно смешно отказался мороженого жаркий летний день затем ту ночь выпил четыре раза калорий алкоголь знаю разум работал это</td>\n",
       "      <td>леденец забавный название знать называться прямо спустя примерно год действительно странный правило питание который включать питьевой вода энергетический напиток видеть это фруктовый мороженое заморозить сок поэтому просто стать очевидный следовать свой правило причина это действительно прижиться посмотреть дело это действительно смешно отказаться мороженое жаркий летний день затем ночь выпить четыре большой калория алкоголь знать разум работать это</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31721</th>\n",
       "      <td>Вы случайно хотели бы, чтобы у вас был близнец? Как будто я просто сижу и случайно думаю: «Было бы круто, если бы у тебя был близнец». Мы оба могли бы носить одинаковую одежду и прически и разыгрывать людей, p.s. Я ЗАВЕВУЮ БЛИЗНЕЦАМ</td>\n",
       "      <td>случайно хотели близнец просто сижу случайно думаю круто близнец оба могли носить одинаковую одежду прически разыгрывать людей завевую близнецам</td>\n",
       "      <td>случайно хотеть близнец просто сидеть случайно думать круто близнец оба мочь носить одинаковый одежда причёска разыгрывать человек завевой близнец</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13089</th>\n",
       "      <td>Если ты читаешь этот банан</td>\n",
       "      <td>читаешь банан</td>\n",
       "      <td>читать банан</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Texts  \\\n",
       "47510                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Мне просто нужна помощь прямо сейчас, я не знаю, что сказать, я просто не могу перестать плакать и боюсь   \n",
       "9847                                                                                                                                                                                                                                                                   Google Meet - это глупо, как будто я захожу на это уже второй час и нажимаю кнопку выключения камеры, прежде чем вы уходите, чтобы присоединиться (как я почти уверен, что 99,9% этого сабвуфера так и делают), и эта кнопка выключила мою камеру в Экран присоединения к собранию, и он НЕ РАБОТАЕТ. Это привело меня на встречу с включенной камерой. Я не могу физически выразить, насколько мне не понравился этот опыт.   \n",
       "16859  леденец – забавное название. я даже не знаю, как они называются\\n\\nя ем один прямо сейчас, спустя примерно 3 года. У меня были действительно странные правила питания, которые включали только питьевую воду и энергетические напитки. я видел в этом фруктовом мороженое замороженный сок, поэтому просто не стал его есть\\n\\nочевидно, я не следовал своим «правилам» на 100%, но по какой-то причине это действительно прижилось, но посмотрите на меня сейчас\\n\\nна самом деле это действительно смешно. я бы отказался от мороженого в жаркий летний день, а затем в ту же ночь выпил бы в четыре раза больше калорий, чем алкоголь\\n\\nя не знаю, как мой разум так работал, но это так   \n",
       "31721                                                                                                                                                                                                                                                                                                                                                                                                                                                      Вы случайно хотели бы, чтобы у вас был близнец? Как будто я просто сижу и случайно думаю: «Было бы круто, если бы у тебя был близнец». Мы оба могли бы носить одинаковую одежду и прически и разыгрывать людей, p.s. Я ЗАВЕВУЮ БЛИЗНЕЦАМ   \n",
       "13089                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Если ты читаешь этот банан   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Tokenised  \\\n",
       "47510                                                                                                                                                                                                                                                                                                                                                                                               просто нужна помощь прямо знаю сказать просто могу перестать плакать боюсь   \n",
       "9847                                                                                                                                                                         google meet это глупо захожу это второй час нажимаю кнопку выключения камеры прежде уходите присоединиться уверен сабвуфера делают эта кнопка выключила мою камеру экран присоединения собранию работает это привело встречу включенной камерой могу физически выразить насколько понравился опыт   \n",
       "16859  леденец забавное название знаю называются ем прямо спустя примерно года действительно странные правила питания которые включали питьевую воду энергетические напитки видел фруктовом мороженое замороженный сок поэтому просто стал очевидно следовал своим правилам причине это действительно прижилось посмотрите самом деле это действительно смешно отказался мороженого жаркий летний день затем ту ночь выпил четыре раза калорий алкоголь знаю разум работал это   \n",
       "31721                                                                                                                                                                                                                                                                                                                         случайно хотели близнец просто сижу случайно думаю круто близнец оба могли носить одинаковую одежду прически разыгрывать людей завевую близнецам   \n",
       "13089                                                                                                                                                                                                                                                                                                                                                                                                                                                            читаешь банан   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Normalised  \n",
       "47510                                                                                                                                                                                                                                                                                                                                                                                         просто нужный помощь прямо знать сказать просто мочь перестать плакать бояться  \n",
       "9847                                                                                                                                                                       google meet это глупо заходить это второй час нажимать кнопка выключение камера прежде уходить присоединиться уверенный это сабвуфер делать кнопка выключить камера экран присоединение собрание работать это привести встреча включить камера мочь физически выразить насколько понравиться опыт  \n",
       "16859  леденец забавный название знать называться прямо спустя примерно год действительно странный правило питание который включать питьевой вода энергетический напиток видеть это фруктовый мороженое заморозить сок поэтому просто стать очевидный следовать свой правило причина это действительно прижиться посмотреть дело это действительно смешно отказаться мороженое жаркий летний день затем ночь выпить четыре большой калория алкоголь знать разум работать это  \n",
       "31721                                                                                                                                                                                                                                                                                                                     случайно хотеть близнец просто сидеть случайно думать круто близнец оба мочь носить одинаковый одежда причёска разыгрывать человек завевой близнец  \n",
       "13089                                                                                                                                                                                                                                                                                                                                                                                                                                                           читать банан  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df[['Texts', 'Tokenised', 'Normalised']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f43aeb8-2c89-48af-94db-564cb3ef9c8f",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287f5337-e9da-40ea-ac76-a8ea83557b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for just tokenised\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Tokenised'], df['Target'], test_size=0.2, stratify=df['Target'], random_state=42)\n",
    "# for normalised docs\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(df['Normalised'], df['Target'], test_size=0.2, stratify=df['Target'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a747ee-7802-4658-844a-08993ef6d471",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53ed7e6c-f8c8-4db5-b33d-4f55a71361ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_transformed = tfidf.fit_transform(X_train)\n",
    "X_test_transformed = tfidf.transform(X_test)\n",
    "\n",
    "tfidf_norm = TfidfVectorizer()\n",
    "X_train_norm_transformed = tfidf_norm.fit_transform(X_train_norm)\n",
    "X_test_norm_transformed = tfidf_norm.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31542d8f-f584-47c3-bd0c-f8facc202728",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6222824-2f8f-4b71-8fa6-123136fe6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "tokens = [doc.split() for doc in X_train]\n",
    "w2v_model = Word2Vec(tokens, vector_size=100, window=5, min_count=5, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6604fbd-ca19-4f66-93c6-7ca49170ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(doc):\n",
    "    tokens = doc.split()\n",
    "    token_vecs = [w2v_model.wv[token] for token in tokens if token in w2v_model.wv]\n",
    "    return np.array(token_vecs).mean(axis=0) if len(token_vecs) != 0 else np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947b47fd-97bf-4d51-9ed5-5fa882ae9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenised\n",
    "X2v_train = np.array([vectorize(doc) for doc in X_train])\n",
    "X2v_test = np.array([vectorize(doc) for doc in X_test])\n",
    "\n",
    "# normalised\n",
    "X2v_train_norm = np.array([vectorize(doc) for doc in X_train_norm])\n",
    "X2v_test_norm = np.array([vectorize(doc) for doc in X_test_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49032944-4576-4a2f-a015-3db84c0fb52f",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1773efe8-e625-4e15-a6d2-37cc4d1040c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def for model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def eval(y_train, X_train, y_test, X_test, model):\n",
    "    print(f\"\"\"\n",
    "    Train:\n",
    "    Accuracy: {round(accuracy_score(y_train, model.predict(X_train)), 3)}\n",
    "    Precision: {round(precision_score(y_train, model.predict(X_train)), 3)}\n",
    "    Recall: {round(recall_score(y_train, model.predict(X_train)), 3)}\n",
    "    F1 score: {round(f1_score(y_train, model.predict(X_train)), 3)}\n",
    "    \n",
    "    Test:\n",
    "    Accuracy: {round(accuracy_score(y_test, model.predict(X_test)), 3)}\n",
    "    Precision: {round(precision_score(y_test, model.predict(X_test)), 3)}\n",
    "    Recall: {round(recall_score(y_test, model.predict(X_test)), 3)}\n",
    "    F1 score: {round(f1_score(y_test, model.predict(X_test)), 3)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59aff1-0ed3-4a66-9c9d-8706f4c21c07",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fabf7f8-7bd6-4e6a-a161-2b57aed67079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.943\n",
      "    Precision: 0.957\n",
      "    Recall: 0.928\n",
      "    F1 score: 0.942\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.914\n",
      "    Precision: 0.932\n",
      "    Recall: 0.893\n",
      "    F1 score: 0.912\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.94\n",
      "    Precision: 0.951\n",
      "    Recall: 0.926\n",
      "    F1 score: 0.939\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.919\n",
      "    Precision: 0.932\n",
      "    Recall: 0.903\n",
      "    F1 score: 0.918\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logclf, logclf_norm = LogisticRegression(n_jobs=-1), LogisticRegression(n_jobs=-1) \n",
    "logclf.fit(X_train_transformed, y_train)\n",
    "logclf_norm.fit(X_train_norm_transformed, y_train)\n",
    "\n",
    "print('LogisticRegression')\n",
    "print('Tokenised')\n",
    "eval(y_train, X_train_transformed, y_test, X_test_transformed, logclf)\n",
    "print('Normalised')\n",
    "eval(y_train, X_train_norm_transformed, y_test, X_test_norm_transformed, logclf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be2bd4c5-a924-4769-93da-d1a4a4107eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.878\n",
      "    Precision: 0.809\n",
      "    Recall: 0.987\n",
      "    F1 score: 0.889\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.832\n",
      "    Precision: 0.755\n",
      "    Recall: 0.983\n",
      "    F1 score: 0.854\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.879\n",
      "    Precision: 0.815\n",
      "    Recall: 0.98\n",
      "    F1 score: 0.89\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.861\n",
      "    Precision: 0.793\n",
      "    Recall: 0.976\n",
      "    F1 score: 0.875\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnbclf, mnbclf_norm  = MultinomialNB(), MultinomialNB() \n",
    "mnbclf.fit(X_train_transformed, y_train)\n",
    "mnbclf_norm.fit(X_train_norm_transformed, y_train)\n",
    "\n",
    "print('MultinomialNB')\n",
    "print('Tokenised')\n",
    "eval(y_train, X_train_transformed, y_test, X_test_transformed, mnbclf)\n",
    "print('Normalised')\n",
    "eval(y_train, X_train_norm_transformed, y_test, X_test_norm_transformed, mnbclf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b108fd81-0eb2-444a-bcdb-bb9a92c3229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.988\n",
      "    Precision: 0.987\n",
      "    Recall: 0.989\n",
      "    F1 score: 0.988\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.919\n",
      "    Precision: 0.934\n",
      "    Recall: 0.902\n",
      "    F1 score: 0.918\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.983\n",
      "    Precision: 0.983\n",
      "    Recall: 0.983\n",
      "    F1 score: 0.983\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.926\n",
      "    Precision: 0.936\n",
      "    Recall: 0.914\n",
      "    F1 score: 0.925\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "svc, svc_norm = SVC(random_state=42), SVC(random_state=42)\n",
    "with joblib.parallel_backend(backend='loky', n_jobs=5):\n",
    "    svc.fit(X_train_transformed, y_train)\n",
    "    svc_norm.fit(X_train_norm_transformed, y_train)\n",
    "\n",
    "print('SVC')\n",
    "print('Tokenised')\n",
    "eval(y_train, X_train_transformed, y_test, X_test_transformed, svc)\n",
    "print('Normalised')\n",
    "eval(y_train, X_train_norm_transformed, y_test, X_test_norm_transformed, svc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96076863-9951-4962-88d0-d1753b74da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.943\n",
      "    Precision: 0.957\n",
      "    Recall: 0.928\n",
      "    F1 score: 0.942\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.914\n",
      "    Precision: 0.931\n",
      "    Recall: 0.895\n",
      "    F1 score: 0.912\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.94\n",
      "    Precision: 0.95\n",
      "    Recall: 0.929\n",
      "    F1 score: 0.94\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.922\n",
      "    Precision: 0.932\n",
      "    Recall: 0.909\n",
      "    F1 score: 0.921\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd, sgd_norm = SGDClassifier(n_jobs=-1), SGDClassifier(n_jobs=-1)\n",
    "sgd.fit(X_train_transformed, y_train)\n",
    "sgd_norm.fit(X_train_norm_transformed, y_train)\n",
    "\n",
    "print('SGD')\n",
    "print('Tokenised')\n",
    "eval(y_train, X_train_transformed, y_test, X_test_transformed, sgd)\n",
    "print('Normalised')\n",
    "eval(y_train, X_train_norm_transformed, y_test, X_test_norm_transformed, sgd_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70de65c-4cf4-4fd8-999d-a78a0c5597c4",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd26c92-42bd-4cb6-94da-2674db3325de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.661\n",
      "    Precision: 0.687\n",
      "    Recall: 0.587\n",
      "    F1 score: 0.633\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.655\n",
      "    Precision: 0.68\n",
      "    Recall: 0.582\n",
      "    F1 score: 0.627\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.678\n",
      "    Precision: 0.688\n",
      "    Recall: 0.647\n",
      "    F1 score: 0.667\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.672\n",
      "    Precision: 0.679\n",
      "    Recall: 0.65\n",
      "    F1 score: 0.664\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "logclf2v, logclf2v_norm = LogisticRegression(n_jobs=-1), LogisticRegression(n_jobs=-1) \n",
    "logclf2v.fit(X2v_train, y_train)\n",
    "logclf2v_norm.fit(X2v_train_norm, y_train)\n",
    "\n",
    "print('LogisticRegression')\n",
    "print('Tokenised')\n",
    "eval(y_train, X2v_train, y_test, X2v_test, logclf2v)\n",
    "print('Normalised')\n",
    "eval(y_train, X2v_train_norm, y_test, X2v_test_norm, logclf2v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb7ba2a3-6ea4-4e28-931b-222c86066cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.632\n",
      "    Precision: 0.689\n",
      "    Recall: 0.478\n",
      "    F1 score: 0.564\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.632\n",
      "    Precision: 0.684\n",
      "    Recall: 0.485\n",
      "    F1 score: 0.567\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.653\n",
      "    Precision: 0.693\n",
      "    Recall: 0.543\n",
      "    F1 score: 0.609\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.64\n",
      "    Precision: 0.674\n",
      "    Recall: 0.537\n",
      "    F1 score: 0.598\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X2v_train_scaled = scaler.fit_transform(X2v_train)\n",
    "X2v_test_scaled = scaler.transform(X2v_test)\n",
    "\n",
    "X2v_train_norm_scaled = scaler.fit_transform(X2v_train_norm)\n",
    "X2v_test_norm_scaled = scaler.transform(X2v_test_norm)\n",
    "\n",
    "mnbclf2v, mnbclf2v_norm = MultinomialNB(), MultinomialNB() \n",
    "mnbclf2v.fit(X2v_train_scaled, y_train)\n",
    "mnbclf2v_norm.fit(X2v_train_norm_scaled, y_train)\n",
    "\n",
    "print('MultinomialNB')\n",
    "print('Tokenised')\n",
    "eval(y_train, X2v_train_scaled, y_test, X2v_test_scaled, mnbclf2v)\n",
    "print('Normalised')\n",
    "eval(y_train, X2v_train_norm_scaled, y_test, X2v_test_norm_scaled, mnbclf2v_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02f50c7e-439e-46ba-baec-25329a1de9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "Tokenised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.5\n",
      "    Precision: 0.499\n",
      "    Recall: 1.0\n",
      "    F1 score: 0.666\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.5\n",
      "    Precision: 0.499\n",
      "    Recall: 1.0\n",
      "    F1 score: 0.666\n",
      "    \n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.498\n",
      "    Precision: 0.498\n",
      "    Recall: 1.0\n",
      "    F1 score: 0.665\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.498\n",
      "    Precision: 0.498\n",
      "    Recall: 1.0\n",
      "    F1 score: 0.665\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd2v, sgd2v_norm = SGDClassifier(n_jobs=-1), SGDClassifier(n_jobs=-1)\n",
    "sgd2v.fit(X2v_train, y_train)\n",
    "sgd2v_norm.fit(X2v_train_norm, y_train)\n",
    "\n",
    "print('SGD')\n",
    "print('Tokenised')\n",
    "eval(y_train, X2v_train, y_test, X2v_test, sgd2v)\n",
    "print('Normalised')\n",
    "eval(y_train, X2v_train_norm, y_test, X2v_test_norm, sgd2v_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b473031-5d28-4e2c-bc99-f3fc41be9d5e",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9380a-81a1-4b0c-b409-8852fa3b95fc",
   "metadata": {},
   "source": [
    "Лучший recall при неплохих других метриках показывает Наивный Байесовский классификатор при приведении токенов к нормальной форме. Теперь можно выбрать гиперпараметры для улучшения модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b411269d-2b70-4e41-8413-ccfdab72ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "Normalised\n",
      "\n",
      "    Train:\n",
      "    Accuracy: 0.879\n",
      "    Precision: 0.815\n",
      "    Recall: 0.98\n",
      "    F1 score: 0.89\n",
      "    \n",
      "    Test:\n",
      "    Accuracy: 0.861\n",
      "    Precision: 0.793\n",
      "    Recall: 0.976\n",
      "    F1 score: 0.875\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gridclf = GridSearchCV(\n",
    "    estimator=MultinomialNB(),\n",
    "    param_grid = {\"alpha\": [0.00001, 0.0001, 0.001, 0.1, 1.0, 10, 50, 100, 200, 500]},\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "gridclf.fit(X_train_norm_transformed, y_train)\n",
    "print(gridclf.best_params_)\n",
    "print('Normalised')\n",
    "eval(y_train, X_train_norm_transformed, y_test, X_test_norm_transformed, gridclf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
